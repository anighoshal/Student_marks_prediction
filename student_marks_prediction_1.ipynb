{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "student_marks_prediction_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDFJC8QMZeI-",
        "outputId": "835c567f-5e4c-4318-bc48-125923f9f86a"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('student-marks-prediction')\n",
        "jovian.set_colab_id('1nIwDCxwrM1y-FT7Hh06lK6kOFzVFkcnN')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▉                           | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 30kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 51kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26740TbhA_tm"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('student-marks-prediction')\n",
        "jovian.set_colab_id('1J9O7eF8hPGmw5M5773bU7LzMSkmbWHva')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLHX3bqqA_tu"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyzFDi4GaHRt"
      },
      "source": [
        "## Hello this is `Anirban Ghoshal` and this is my first task of TSF. In this task I have tried to predict a students exam score by his no. of hours of study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iugxyNnNR6q5"
      },
      "source": [
        "## Importing all the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xS-5niWA_tv"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import TensorDataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkQ_hacTSpwA"
      },
      "source": [
        "## Now we will import the data and convert it to PyTorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LgEwSI6BXvw",
        "outputId": "66ffb8a0-fbe8-4be5-b27f-f1eddedf7598"
      },
      "source": [
        "hours = np.array([[2.5000], [5.1000], [3.2000], [8.5000], [3.5000], [1.5000], [9.2000], [5.5000], [8.3000],\r\n",
        "        [2.7000], [7.7000], [5.9000], [4.5000], [3.3000], [1.1000], [8.9000], [2.5000], [1.9000],\r\n",
        "        [6.1000], [7.4000], [2.7000], [4.8000], [3.8000], [6.9000], [7.8000]], dtype='float32')\r\n",
        "\r\n",
        "marks = np.array([[21], [47], [27], [75], [30], [20], [88], [60], [81], [25], [85], [62], [41], [42], [17], [95], [30], [24], [67], [69], [30], [54], [35], [76], [86]], dtype='float32')\r\n",
        "\r\n",
        "hours = torch.from_numpy(hours)\r\n",
        "marks = torch.from_numpy(marks)\r\n",
        "\r\n",
        "print(hours)\r\n",
        "print(marks)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.5000],\n",
            "        [5.1000],\n",
            "        [3.2000],\n",
            "        [8.5000],\n",
            "        [3.5000],\n",
            "        [1.5000],\n",
            "        [9.2000],\n",
            "        [5.5000],\n",
            "        [8.3000],\n",
            "        [2.7000],\n",
            "        [7.7000],\n",
            "        [5.9000],\n",
            "        [4.5000],\n",
            "        [3.3000],\n",
            "        [1.1000],\n",
            "        [8.9000],\n",
            "        [2.5000],\n",
            "        [1.9000],\n",
            "        [6.1000],\n",
            "        [7.4000],\n",
            "        [2.7000],\n",
            "        [4.8000],\n",
            "        [3.8000],\n",
            "        [6.9000],\n",
            "        [7.8000]])\n",
            "tensor([[21.],\n",
            "        [47.],\n",
            "        [27.],\n",
            "        [75.],\n",
            "        [30.],\n",
            "        [20.],\n",
            "        [88.],\n",
            "        [60.],\n",
            "        [81.],\n",
            "        [25.],\n",
            "        [85.],\n",
            "        [62.],\n",
            "        [41.],\n",
            "        [42.],\n",
            "        [17.],\n",
            "        [95.],\n",
            "        [30.],\n",
            "        [24.],\n",
            "        [67.],\n",
            "        [69.],\n",
            "        [30.],\n",
            "        [54.],\n",
            "        [35.],\n",
            "        [76.],\n",
            "        [86.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5UlvRJiTKGg"
      },
      "source": [
        "## Now We'll create a `TensorDataset`, which allows access to rows from `hours` and `marks` as tuples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZTEiwGESoXA",
        "outputId": "afa5c239-bf94-4c65-b5ea-117ad7bcb648"
      },
      "source": [
        "train_ds = TensorDataset(hours, marks)\r\n",
        "train_ds[0:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2.5000],\n",
              "         [5.1000],\n",
              "         [3.2000],\n",
              "         [8.5000],\n",
              "         [3.5000],\n",
              "         [1.5000],\n",
              "         [9.2000],\n",
              "         [5.5000],\n",
              "         [8.3000],\n",
              "         [2.7000]]), tensor([[21.],\n",
              "         [47.],\n",
              "         [27.],\n",
              "         [75.],\n",
              "         [30.],\n",
              "         [20.],\n",
              "         [88.],\n",
              "         [60.],\n",
              "         [81.],\n",
              "         [25.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmbSnt7iTgJn"
      },
      "source": [
        "## Now we will visualize the data to see if there is any linear relation between `hours` and `marks`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ko4WwoyeTSsm",
        "outputId": "b86d30de-eafa-4d74-f760-62eafe70322b"
      },
      "source": [
        "plt.scatter(hours, marks)\r\n",
        "plt.title(\"Hours vs Marks\")\r\n",
        "plt.xlabel(\"Hours Studied\")\r\n",
        "plt.ylabel(\"Marks Score\")\r\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zflEfH6WdHf"
      },
      "source": [
        "So we can see there is a linear relation between the study hours and the marks scored. Now we can perform `Linear regression` using `Gradient descent` algorithm for predicting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddx_nLC6W5-f"
      },
      "source": [
        "## We'll also create a `DataLoader`, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9MrhTLJUKrM"
      },
      "source": [
        "batch_size = 5\r\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9SlLqtqW_QH",
        "outputId": "5cac6682-9e54-467d-ada6-df586a06a2cb"
      },
      "source": [
        "for xb, yb in train_dl:\r\n",
        "    print(xb)\r\n",
        "    print(yb)\r\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.8000],\n",
            "        [4.5000],\n",
            "        [7.4000],\n",
            "        [1.5000],\n",
            "        [4.8000]])\n",
            "tensor([[35.],\n",
            "        [41.],\n",
            "        [69.],\n",
            "        [20.],\n",
            "        [54.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mC850KzXGI_"
      },
      "source": [
        "In each iteration, the data loader returns one batch of data with the given batch size. If `shuffle` is set to `True`, it shuffles the training data before creating batches. Shuffling helps randomize the input to the optimization algorithm, leading to a faster reduction in the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7K5mbIhXfGf"
      },
      "source": [
        "## Now we will define our model using `nn.Linear` class from PyTorch which will give us weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wZtsaGDXDrH",
        "outputId": "36445313-ec31-4b36-f13d-5ccc49c391f1"
      },
      "source": [
        "model = nn.Linear(1, 1)\r\n",
        "print(model.weight)\r\n",
        "print(model.bias)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0742]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2433], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJPhRL0yX6bP"
      },
      "source": [
        "We can use the model to generate predictions in the same way as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_zvCmj4Xubp",
        "outputId": "ff33c586-6967-40da-eec5-2ab78f1824bd"
      },
      "source": [
        "preds = model(hours)\r\n",
        "preds"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4289],\n",
              "        [-0.6218],\n",
              "        [-0.4808],\n",
              "        [-0.8741],\n",
              "        [-0.5031],\n",
              "        [-0.3547],\n",
              "        [-0.9260],\n",
              "        [-0.6515],\n",
              "        [-0.8592],\n",
              "        [-0.4437],\n",
              "        [-0.8147],\n",
              "        [-0.6811],\n",
              "        [-0.5773],\n",
              "        [-0.4882],\n",
              "        [-0.3250],\n",
              "        [-0.9038],\n",
              "        [-0.4289],\n",
              "        [-0.3843],\n",
              "        [-0.6960],\n",
              "        [-0.7925],\n",
              "        [-0.4437],\n",
              "        [-0.5995],\n",
              "        [-0.5253],\n",
              "        [-0.7554],\n",
              "        [-0.8221]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JobXQzwnY3dw"
      },
      "source": [
        "## Loss Function\r\n",
        "Now we will define a loss function for calculating the loss and will try further to twicking the weights and biases for seeing a decrease in the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaDD0bpwX8zZ"
      },
      "source": [
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CJLYbXUZTXX",
        "outputId": "dc455197-dfd0-4444-e534-db4eeb08d6d2"
      },
      "source": [
        "loss = loss_fn(model(hours), marks)\r\n",
        "print(loss)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3336.6794, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeKHTyszZgAI"
      },
      "source": [
        "We will now use a optimizer called `optim.SGD` for manipulating the weights and biases. SGD is short for \"stochastic gradient descent\". The term _stochastic_ indicates that samples are selected in random batches instead of as a single group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK1Ed5VmZYrM"
      },
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsHY3ewnZ_VX"
      },
      "source": [
        "## Train the model\r\n",
        "\r\n",
        "We are now ready to train the model. We'll follow the below steps to implement gradient descent:\r\n",
        "\r\n",
        "1. Generate predictions\r\n",
        "\r\n",
        "2. Calculate the loss\r\n",
        "\r\n",
        "3. Compute gradients w.r.t the weights and biases\r\n",
        "\r\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\r\n",
        "\r\n",
        "5. Reset the gradients to zero\r\n",
        "\r\n",
        "Let's define a utility function `fit` that trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owOtakmyZ16q"
      },
      "source": [
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\r\n",
        "    \r\n",
        "    # Repeat for given number of epochs\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        \r\n",
        "        # Train with batches of data\r\n",
        "        for xb,yb in train_dl:\r\n",
        "            \r\n",
        "            # 1. Generate predictions\r\n",
        "            pred = model(xb)\r\n",
        "            \r\n",
        "            # 2. Calculate loss\r\n",
        "            loss = loss_fn(pred, yb)\r\n",
        "            \r\n",
        "            # 3. Compute gradients\r\n",
        "            loss.backward()\r\n",
        "            \r\n",
        "            # 4. Update parameters using gradients\r\n",
        "            opt.step()\r\n",
        "            \r\n",
        "            # 5. Reset the gradients to zero\r\n",
        "            opt.zero_grad()\r\n",
        "        \r\n",
        "        # Print the progress\r\n",
        "        if (epoch+1) % 100 == 0:\r\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7iH1lvcaUV9",
        "outputId": "47a8f7fb-26e3-4b46-96e5-ab621c3e6cfe"
      },
      "source": [
        "fit(2000, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [100/2000], Loss: 1128.4720\n",
            "Epoch [200/2000], Loss: 1066.3456\n",
            "Epoch [300/2000], Loss: 775.7544\n",
            "Epoch [400/2000], Loss: 390.4615\n",
            "Epoch [500/2000], Loss: 114.0930\n",
            "Epoch [600/2000], Loss: 89.3117\n",
            "Epoch [700/2000], Loss: 44.0432\n",
            "Epoch [800/2000], Loss: 44.4283\n",
            "Epoch [900/2000], Loss: 19.5621\n",
            "Epoch [1000/2000], Loss: 41.9519\n",
            "Epoch [1100/2000], Loss: 31.2088\n",
            "Epoch [1200/2000], Loss: 38.9420\n",
            "Epoch [1300/2000], Loss: 32.9424\n",
            "Epoch [1400/2000], Loss: 17.0594\n",
            "Epoch [1500/2000], Loss: 28.7098\n",
            "Epoch [1600/2000], Loss: 38.4533\n",
            "Epoch [1700/2000], Loss: 29.1903\n",
            "Epoch [1800/2000], Loss: 31.4935\n",
            "Epoch [1900/2000], Loss: 46.8322\n",
            "Epoch [2000/2000], Loss: 36.5214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL5M-VBiabF4"
      },
      "source": [
        "We have trained our model for 2000 epochs and we got the Loss value 19.32 which is pretty good compared to the first loss value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gU_vFbNauPf"
      },
      "source": [
        "### Now we will see how good our model has performed and we will try to predict if a student studies for `9.25 hours` then what will be the score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4xbPd6HaXw-",
        "outputId": "afddb9ef-0b42-4918-f49f-f82b4770e0f3"
      },
      "source": [
        "preds = model(hours)\r\n",
        "preds"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[26.2432],\n",
              "        [52.0652],\n",
              "        [33.1952],\n",
              "        [85.8324],\n",
              "        [36.1747],\n",
              "        [16.3116],\n",
              "        [92.7844],\n",
              "        [56.0378],\n",
              "        [83.8461],\n",
              "        [28.2295],\n",
              "        [77.8871],\n",
              "        [60.0104],\n",
              "        [46.1062],\n",
              "        [34.1884],\n",
              "        [12.3390],\n",
              "        [89.8050],\n",
              "        [26.2432],\n",
              "        [20.2842],\n",
              "        [61.9967],\n",
              "        [74.9077],\n",
              "        [28.2295],\n",
              "        [49.0857],\n",
              "        [39.1542],\n",
              "        [69.9419],\n",
              "        [78.8803]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ctwrNf2bE5b",
        "outputId": "1350702b-6421-4013-daa9-f6d07f97b447"
      },
      "source": [
        "marks"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[21.],\n",
              "        [47.],\n",
              "        [27.],\n",
              "        [75.],\n",
              "        [30.],\n",
              "        [20.],\n",
              "        [88.],\n",
              "        [60.],\n",
              "        [81.],\n",
              "        [25.],\n",
              "        [85.],\n",
              "        [62.],\n",
              "        [41.],\n",
              "        [42.],\n",
              "        [17.],\n",
              "        [95.],\n",
              "        [30.],\n",
              "        [24.],\n",
              "        [67.],\n",
              "        [69.],\n",
              "        [30.],\n",
              "        [54.],\n",
              "        [35.],\n",
              "        [76.],\n",
              "        [86.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xixqsSRObNM_"
      },
      "source": [
        "Let's see for 9.25 hours how much a student scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk17TzvObI9O",
        "outputId": "0015fef4-15aa-4138-f402-36f690c6452e"
      },
      "source": [
        "model(torch.tensor([[9.2500]]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[93.2810]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgAyMPzLZUMr",
        "outputId": "b88db4d4-131b-47d4-bb43-4bf29f622c5b"
      },
      "source": [
        "model(torch.tensor([[1.0000]]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11.3459]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t355l-xPbZOX"
      },
      "source": [
        "The predicted score is 92.67"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "oWpVysvfcEPA",
        "outputId": "68ac3da2-6ba9-48ef-97a4-518cd36802ca"
      },
      "source": [
        "import jovian\r\n",
        "jovian.commit()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/anirbanghoshal990/student-marks-prediction\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/anirbanghoshal990/student-marks-prediction'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr7R0fWymlU8"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}